{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7J+rrG5VU9yURBU4cu2AB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishal8500/Parkinson-Disease-Prediction/blob/main/Speech_parkinson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Paths to your folders\n",
        "parkinsons_path = \"/content/dataset/Parkinson\"\n",
        "healthy_path = \"/content/dataset/Heathly\"\n",
        "\n",
        "# Helper function to load, normalize, and resample\n",
        "def process_audio(file_path, target_sr=22050):\n",
        "    y, sr = librosa.load(file_path, sr=None)  # Original sampling rate\n",
        "    y = y / np.max(np.abs(y))  # Normalize to [-1, 1]\n",
        "    if sr != target_sr:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "    return y, target_sr\n",
        "\n",
        "# Create dataset lists\n",
        "audio_data = []\n",
        "labels = []\n",
        "\n",
        "# Load Parkinson's patients (label 1)\n",
        "for file in os.listdir(parkinsons_path):\n",
        "    if file.endswith('.wav'):\n",
        "        path = os.path.join(parkinsons_path, file)\n",
        "        y, sr = process_audio(path)\n",
        "        audio_data.append(y)\n",
        "        labels.append(1)\n",
        "\n",
        "# Load Healthy persons (label 0)\n",
        "for file in os.listdir(healthy_path):\n",
        "    if file.endswith('.wav'):\n",
        "        path = os.path.join(healthy_path, file)\n",
        "        y, sr = process_audio(path)\n",
        "        audio_data.append(y)\n",
        "        labels.append(0)\n",
        "\n",
        "print(f\"Total samples: {len(audio_data)} (Parkinson's: {labels.count(1)}, Healthy: {labels.count(0)})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDXfp3c1FQsn",
        "outputId": "adeada2f-2304-4d4b-9410-a4a51f37c979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 81 (Parkinson's: 40, Healthy: 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6k4tnWRH11M",
        "outputId": "a3013d5c-1042-4543-e743-7befb161cef2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from noisereduce) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\n",
            "Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import noisereduce as nr\n",
        "import librosa.display\n",
        "\n",
        "# Function: Preprocess, Frame, Apply Window, and STFT\n",
        "def preprocess_and_convert_to_mel(file_path, target_sr=22050, frame_length=2048, hop_length=512, n_mels=128, target_length=66150):\n",
        "    # 1. Load Audio\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # 2. Resample (if needed)\n",
        "    if sr != target_sr:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "\n",
        "    # 3. Normalize to [-1, 1]\n",
        "    y = y / np.max(np.abs(y))\n",
        "\n",
        "    # 4. Trim Silence (30 dB threshold)\n",
        "    y, _ = librosa.effects.trim(y, top_db=30)\n",
        "\n",
        "    # 5. Noise Reduction (Optional)\n",
        "    y = nr.reduce_noise(y=y, sr=target_sr)\n",
        "\n",
        "    # 6. Pad/Truncate to Fixed Length\n",
        "    if len(y) < target_length:\n",
        "        y = np.pad(y, (0, target_length - len(y)))\n",
        "    else:\n",
        "        y = y[:target_length]\n",
        "\n",
        "    # 7. Framing: Split audio into overlapping frames\n",
        "    frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length).T\n",
        "\n",
        "    # 8. Windowing: Apply a Hamming window to each frame\n",
        "    window = np.hamming(frame_length)\n",
        "    windowed_frames = frames * window\n",
        "\n",
        "    # 9. Apply STFT to convert to the frequency domain\n",
        "    stft = librosa.stft(y, n_fft=frame_length, hop_length=hop_length, window='hamming')\n",
        "\n",
        "    # 10. Convert to Mel Spectrogram\n",
        "    mel_spec = librosa.feature.melspectrogram(S=np.abs(stft)**2, sr=target_sr, n_mels=n_mels)\n",
        "\n",
        "    # 11. Convert Power to dB Scale\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    return mel_spec_db"
      ],
      "metadata": {
        "id": "kkEZAaqgF63e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def process_dataset(parkinsons_path, healthy_path, output_dir):\n",
        "    # Create subfolders for each class\n",
        "    parkinsons_folder = os.path.join(output_dir, \"parkinson\")\n",
        "    healthy_folder = os.path.join(output_dir, \"healthy\")\n",
        "    os.makedirs(parkinsons_folder, exist_ok=True)\n",
        "    os.makedirs(healthy_folder, exist_ok=True)\n",
        "\n",
        "    labels = []\n",
        "    all_mels = []\n",
        "\n",
        "    # Use a list of tuples to iterate\n",
        "    for label, (class_path, output_folder) in enumerate(\n",
        "            [(parkinsons_path, parkinsons_folder), (healthy_path, healthy_folder)]):\n",
        "        for file in os.listdir(class_path):\n",
        "            if file.endswith('.wav'):\n",
        "                file_path = os.path.join(class_path, file)\n",
        "\n",
        "                # Preprocess and convert to Mel Spectrogram\n",
        "                mel_spec = preprocess_and_convert_to_mel(file_path)\n",
        "\n",
        "                # Save the Mel spectrogram as a .npy file in the respective class folder\n",
        "                output_file = os.path.join(output_folder, f\"{file.replace('.wav', '.npy')}\")\n",
        "                np.save(output_file, mel_spec)\n",
        "\n",
        "                all_mels.append(output_file)\n",
        "                labels.append(label)\n",
        "\n",
        "    print(f\"✅ Processed {len(all_mels)} samples (Parkinson's: {labels.count(0)}, Healthy: {labels.count(1)})\")\n",
        "    return all_mels, labels\n",
        "\n",
        "# Paths to Dataset\n",
        "parkinsons_path = \"/content/dataset/Parkinson\"\n",
        "healthy_path = \"/content/dataset/Heathly\"\n",
        "output_dir = \"/content/mel_spectrograms/\"\n",
        "\n",
        "# Process Dataset and Save Mel Spectrograms\n",
        "mels, labels = process_dataset(parkinsons_path, healthy_path, output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9MdgOA2H7Bk",
        "outputId": "173d8dde-318b-4538-808d-54ff440741b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed 81 samples (Parkinson's: 40, Healthy: 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_mel_as_image(npy_file, image_path):\n",
        "    # Load the Mel spectrogram from the .npy file\n",
        "    mel_spec = np.load(npy_file)\n",
        "\n",
        "    # Create the image and save it\n",
        "    plt.figure(figsize=(mel_spec.shape[1] / 100, mel_spec.shape[0] / 100), dpi=100)\n",
        "    plt.imshow(mel_spec, cmap='inferno', aspect='auto', origin='lower')\n",
        "    plt.axis('off')  # Hide axes for cleaner image\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the image to the specified path\n",
        "    plt.savefig(image_path, bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "    # Close the plot to avoid memory issues\n",
        "    plt.close()\n",
        "\n",
        "def convert_npy_to_images(mel_dir, output_image_dir):\n",
        "    # Iterate through each class (parkinson and healthy)\n",
        "    for class_folder in os.listdir(mel_dir):\n",
        "        class_folder_path = os.path.join(mel_dir, class_folder)\n",
        "\n",
        "        # Check if it is a directory (parkinson or healthy)\n",
        "        if os.path.isdir(class_folder_path):\n",
        "            # Create the corresponding class folder in the output directory\n",
        "            class_output_folder = os.path.join(output_image_dir, class_folder)\n",
        "            os.makedirs(class_output_folder, exist_ok=True)\n",
        "\n",
        "            # Process each .npy file in the class folder\n",
        "            for file in os.listdir(class_folder_path):\n",
        "                if file.endswith('.npy'):\n",
        "                    npy_file_path = os.path.join(class_folder_path, file)\n",
        "\n",
        "                    # Define the output image path\n",
        "                    image_path = os.path.join(class_output_folder, file.replace('.npy', '.png'))\n",
        "\n",
        "                    # Save the Mel spectrogram as an image\n",
        "                    save_mel_as_image(npy_file_path, image_path)\n",
        "\n",
        "    print(f\"✅ Converted Mel spectrograms to images in {output_image_dir}\")\n",
        "\n",
        "# Define the directory with Mel spectrogram .npy files\n",
        "mel_spectrogram_dir = \"/content/mel_spectrograms/\"\n",
        "output_image_dir = \"/content/mel_spectrogram_images/\"\n",
        "\n",
        "# Convert Mel spectrograms to images and preserve folder structure\n",
        "convert_npy_to_images(mel_spectrogram_dir, output_image_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE5jRcUyKVud",
        "outputId": "0a4243c7-d39a-4193-8b97-ee081162cada"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Converted Mel spectrograms to images in /content/mel_spectrogram_images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def resize_and_replace_images(image_dir, target_size=(224, 224)):\n",
        "    # Iterate through each image in the directory\n",
        "    for class_folder in os.listdir(image_dir):\n",
        "        class_folder_path = os.path.join(image_dir, class_folder)\n",
        "\n",
        "        # Check if it is a directory (parkinson or healthy)\n",
        "        if os.path.isdir(class_folder_path):\n",
        "            # Process each image in the class folder\n",
        "            for file in os.listdir(class_folder_path):\n",
        "                if file.endswith('.png'):\n",
        "                    image_path = os.path.join(class_folder_path, file)\n",
        "\n",
        "                    # Open the image using PIL\n",
        "                    img = Image.open(image_path)\n",
        "\n",
        "                    # Resize the image\n",
        "                    img_resized = img.resize(target_size)\n",
        "\n",
        "                    # Save the resized image, replacing the original one\n",
        "                    img_resized.save(image_path)\n",
        "\n",
        "    print(f\"✅ Resized and replaced images in {image_dir}\")\n",
        "\n",
        "# Define the directory with Mel spectrogram images\n",
        "mel_spectrogram_image_dir = \"/content/mel_spectrogram_images/\"\n",
        "\n",
        "# Resize and replace original images with the new ones\n",
        "resize_and_replace_images(mel_spectrogram_image_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1S1yizsPztA",
        "outputId": "6ab912a3-6e5c-4579-cac8-a18768094330"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Resized and replaced images in /content/mel_spectrogram_images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up the image size for resizing\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Define paths\n",
        "image_dir = \"/content/mel_spectrogram_images/\"  # Change this to your mel spectrogram images directory\n",
        "augmented_dir = \"/content/mel_spectrogram_images/augmented\"  # Augmented images will be saved here\n",
        "\n",
        "# Set up ImageDataGenerator with augmentations\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Rotate images within 20 degrees\n",
        "    width_shift_range=0.2,  # Shift images horizontally by 20%\n",
        "    height_shift_range=0.2,  # Shift images vertically by 20%\n",
        "    shear_range=0.2,  # Apply shearing transformations\n",
        "    zoom_range=0.2,  # Zoom in or out on images by 20%\n",
        "    horizontal_flip=True,  # Flip images horizontally\n",
        "    fill_mode='nearest'  # Fill pixels that were transformed\n",
        ")\n",
        "\n",
        "# Function to apply augmentation and save images\n",
        "def augment_and_save_images(image_dir):\n",
        "    for class_folder in os.listdir(image_dir):\n",
        "        class_folder_path = os.path.join(image_dir, class_folder)\n",
        "\n",
        "        # Check if it is a directory (parkinson or healthy)\n",
        "        if os.path.isdir(class_folder_path):\n",
        "            # Create the corresponding folder in the augmented directory\n",
        "            class_output_folder = os.path.join(augmented_dir, class_folder)\n",
        "            os.makedirs(class_output_folder, exist_ok=True)\n",
        "\n",
        "            # Process each .png file in the class folder\n",
        "            for file in os.listdir(class_folder_path):\n",
        "                if file.endswith('.png'):  # Process only .png images\n",
        "                    image_path = os.path.join(class_folder_path, file)\n",
        "\n",
        "                    # Load the image\n",
        "                    img = load_img(image_path)\n",
        "                    x = img_to_array(img)\n",
        "                    x = x.reshape((1,) + x.shape)  # Reshape for augmentation\n",
        "\n",
        "                    # Generate batches of augmented images and save them\n",
        "                    i = 0\n",
        "                    for batch in datagen.flow(x, batch_size=1, save_to_dir=class_output_folder, save_prefix='aug', save_format='png'):\n",
        "                        i += 1\n",
        "                        if i > 10:  # Generate 10 augmented images per original image\n",
        "                            break\n",
        "\n",
        "    print(\"✅ Augmentation and saving completed!\")\n",
        "\n",
        "# Function to oversample the minority class\n",
        "def oversample_class(class_folder_path, target_count):\n",
        "    # Get list of image files in the class folder\n",
        "    files = [f for f in os.listdir(class_folder_path) if f.endswith('.png')]\n",
        "\n",
        "    # Calculate how many samples are needed to reach the target count\n",
        "    while len(files) < target_count:\n",
        "        # Randomly select a file to duplicate\n",
        "        file_to_duplicate = random.choice(files)\n",
        "\n",
        "        # Create a copy of the selected file in the same folder\n",
        "        shutil.copy(os.path.join(class_folder_path, file_to_duplicate), os.path.join(class_folder_path, f\"dup_{len(files)}.png\"))\n",
        "        files.append(f\"dup_{len(files)}.png\")\n",
        "\n",
        "    print(f\"✅ Oversampled {class_folder_path} to {target_count} images\")\n",
        "\n",
        "# Run the augmentation\n",
        "augment_and_save_images(image_dir)\n",
        "\n",
        "# Example: Oversample the Parkinson's class to 200 images\n",
        "parkinson_folder = os.path.join(image_dir, 'parkinson')\n",
        "oversample_class(parkinson_folder, target_count=200)\n",
        "\n",
        "# Example: Oversample the Healthy class to 200 images\n",
        "healthy_folder = os.path.join(image_dir, 'healthy')\n",
        "oversample_class(healthy_folder, target_count=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj9xVdCvP-qL",
        "outputId": "0882c5db-6558-4fb9-b87b-2cb26d92af67"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Augmentation and saving completed!\n",
            "✅ Oversampled /content/mel_spectrogram_images/parkinson to 200 images\n",
            "✅ Oversampled /content/mel_spectrogram_images/healthy to 200 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_dataset(source_dir, output_dir, split_ratio=0.9):\n",
        "    # Create the directories for train and validation\n",
        "    train_dir = os.path.join(output_dir, 'train')\n",
        "    valid_dir = os.path.join(output_dir, 'validation')\n",
        "\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(valid_dir, exist_ok=True)\n",
        "\n",
        "    # Loop through each class (parkinson and healthy)\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "\n",
        "        # Check if it's a directory (parkinson or healthy)\n",
        "        if os.path.isdir(class_path):\n",
        "            # Create subdirectories for train and validation within each class folder\n",
        "            train_class_dir = os.path.join(train_dir, class_name)\n",
        "            valid_class_dir = os.path.join(valid_dir, class_name)\n",
        "            os.makedirs(train_class_dir, exist_ok=True)\n",
        "            os.makedirs(valid_class_dir, exist_ok=True)\n",
        "\n",
        "            # Get all .png files for the current class\n",
        "            files = [f for f in os.listdir(class_path) if f.endswith('.png')]\n",
        "\n",
        "            # Shuffle the files to ensure random splitting\n",
        "            random.shuffle(files)\n",
        "\n",
        "            # Calculate the number of files for the training set\n",
        "            num_train = int(len(files) * split_ratio)\n",
        "\n",
        "            # Move files to the corresponding directories (train/validation)\n",
        "            for i, file in enumerate(files):\n",
        "                src = os.path.join(class_path, file)\n",
        "\n",
        "                if i < num_train:\n",
        "                    dest = os.path.join(train_class_dir, file)\n",
        "                else:\n",
        "                    dest = os.path.join(valid_class_dir, file)\n",
        "\n",
        "                # Copy the file to the destination\n",
        "                shutil.copy2(src, dest)\n",
        "\n",
        "    print(f\"✅ Dataset split completed. Training set: {len(os.listdir(train_class_dir))} files, Validation set: {len(os.listdir(valid_class_dir))} files\")\n",
        "\n",
        "# Define the source directory and the output directory for the split\n",
        "source_dir = '/content/mel_spectrogram_images/augmented'\n",
        "output_dir = '/content/split_mel_spectrograms'\n",
        "\n",
        "# Split the dataset into train and validation sets (90-10 split)\n",
        "split_dataset(source_dir, output_dir, split_ratio=0.9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA1IZn5nRQe7",
        "outputId": "fe1e589a-7d1a-4f0f-9186-5742cfe0a327"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset split completed. Training set: 386 files, Validation set: 43 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Prompt user for folder path\n",
        "folder_path = input(\"Enter the folder path to delete all files: \")\n",
        "\n",
        "# Check if folder exists\n",
        "if os.path.exists(folder_path):\n",
        "    # Delete all files in the folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.remove(file_path)  # Delete file or symlink\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)  # Delete folder and contents\n",
        "            print(f\"Deleted: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file_path}: {e}\")\n",
        "    print(\"All files deleted successfully.\")\n",
        "else:\n",
        "    print(\"Folder not found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8J1uwt7LVu-",
        "outputId": "13275683-d58d-40af-b547-5e1439c2a001"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the folder path to delete all files: /content/split_mel_spectrograms\n",
            "Deleted: /content/split_mel_spectrograms/validation\n",
            "Deleted: /content/split_mel_spectrograms/train\n",
            "All files deleted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load ResNet50 model with pre-trained weights and exclude the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze all layers except the top layers\n",
        "base_model.trainable = False  # Freeze all layers in the base model initially\n",
        "\n",
        "# Add custom layers on top of ResNet50\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Add Dropout for regularization\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)  # Binary classification output\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model (use a low learning rate for fine-tuning)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the frozen base model\n",
        "history = model.fit(train_generator, epochs=15, steps_per_epoch=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTAnsspSXJdO",
        "outputId": "0d559b53-e2f4-46ac-e8eb-11c582b75eb1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.4971 - loss: 1.3298\n",
            "Epoch 2/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.4817 - loss: 0.9366 \n",
            "Epoch 3/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 108ms/step - accuracy: 0.4767 - loss: 0.7243\n",
            "Epoch 4/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 109ms/step - accuracy: 0.4813 - loss: 0.7007\n",
            "Epoch 5/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 124ms/step - accuracy: 0.4914 - loss: 0.6932\n",
            "Epoch 6/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.4720 - loss: 0.6932\n",
            "Epoch 7/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.5091 - loss: 0.6932\n",
            "Epoch 8/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - accuracy: 0.5115 - loss: 0.6931\n",
            "Epoch 9/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step - accuracy: 0.5049 - loss: 0.6931\n",
            "Epoch 10/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - accuracy: 0.5185 - loss: 0.6931\n",
            "Epoch 11/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.5057 - loss: 0.6932\n",
            "Epoch 12/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.5086 - loss: 0.6931\n",
            "Epoch 13/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.5041 - loss: 0.6932\n",
            "Epoch 14/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.5100 - loss: 0.6931\n",
            "Epoch 15/15\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.4951 - loss: 0.6932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "base_model.trainable = True  # Unfreeze all layers\n",
        "fine_tune_at = 100  # Fine-tune from layer 100 onwards\n",
        "\n",
        "# Freeze layers before the fine-tune layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile the model after making layers trainable\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continue training the model with a low learning rate\n",
        "history_finetune = model.fit(train_generator, epochs=5, steps_per_epoch=100)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "loss, accuracy = model.evaluate(valid_generator)\n",
        "print(f\"Validation Loss: {loss}\")\n",
        "print(f\"Validation Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "1qrAWVyzYauC",
        "outputId": "7ba76842-75f4-4560-ea46-326508c397dd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 242ms/step - accuracy: 0.5037 - loss: 1.0039 \n",
            "Epoch 2/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 128ms/step - accuracy: 0.4947 - loss: 0.8878\n",
            "Epoch 3/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 121ms/step - accuracy: 0.4967 - loss: 0.8014\n",
            "Epoch 4/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - accuracy: 0.5112 - loss: 0.7858\n",
            "Epoch 5/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - accuracy: 0.5145 - loss: 0.7432\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'valid_generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-e1fa62158eeb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Evaluate the model on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Accuracy: {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_generator' is not defined"
          ]
        }
      ]
    }
  ]
}